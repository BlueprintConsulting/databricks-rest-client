/*
 * Jobs API 2.1
 * The Jobs API allows you to create, edit, and delete jobs.
 *
 * The version of the OpenAPI document: 2.1
 *
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package com.edmunds.rest.databricks.DTO.jobs;

import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonPropertyOrder;

import java.util.ArrayList;
import java.util.List;
import java.util.Objects;

;


/**
 * SparkPythonTaskDTO
 */
@JsonPropertyOrder({
        SparkPythonTaskDTO.JSON_PROPERTY_PYTHON_FILE,
        SparkPythonTaskDTO.JSON_PROPERTY_PARAMETERS
})
@javax.annotation.Generated(value = "org.openapitools.codegen.languages.JavaJerseyServerCodegen", date = "2022-03-09T23:53:34.566-08:00[America/Los_Angeles]")
public class SparkPythonTaskDTO {
    public static final String JSON_PROPERTY_PYTHON_FILE = "python_file";
    public static final String JSON_PROPERTY_PARAMETERS = "parameters";
    @JsonProperty(JSON_PROPERTY_PYTHON_FILE)
    private String pythonFile;
    @JsonProperty(JSON_PROPERTY_PARAMETERS)
    private List<String> parameters = null;

    public SparkPythonTaskDTO pythonFile(String pythonFile) {
        this.pythonFile = pythonFile;
        return this;
    }

    /**
     * The URI of the Python file to be executed. DBFS paths are supported. This field is required.
     *
     * @return pythonFile
     **/
    @JsonProperty(value = "python_file")

    public String getPythonFile() {
        return pythonFile;
    }

    public void setPythonFile(String pythonFile) {
        this.pythonFile = pythonFile;
    }

    public SparkPythonTaskDTO parameters(List<String> parameters) {
        this.parameters = parameters;
        return this;
    }

    public SparkPythonTaskDTO addParametersItem(String parametersItem) {
        if (this.parameters == null) {
            this.parameters = new ArrayList<String>();
        }
        this.parameters.add(parametersItem);
        return this;
    }

    /**
     * Command line parameters passed to the Python file.  Use [Task parameter variables](https://docs.microsoft.com/azure/databricks/jobs#parameter-variables) to set parameters containing information about job runs.
     *
     * @return parameters
     **/
    @JsonProperty(value = "parameters")

    public List<String> getParameters() {
        return parameters;
    }

    public void setParameters(List<String> parameters) {
        this.parameters = parameters;
    }


    @Override
    public boolean equals(Object o) {
        if (this == o) {
            return true;
        }
        if (o == null || getClass() != o.getClass()) {
            return false;
        }
        SparkPythonTaskDTO sparkPythonTask = (SparkPythonTaskDTO) o;
        return Objects.equals(this.pythonFile, sparkPythonTask.pythonFile) &&
                Objects.equals(this.parameters, sparkPythonTask.parameters);
    }

    @Override
    public int hashCode() {
        return Objects.hash(pythonFile, parameters);
    }


    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder();
        sb.append("class SparkPythonTaskDTO {\n");

        sb.append("    pythonFile: ").append(toIndentedString(pythonFile)).append("\n");
        sb.append("    parameters: ").append(toIndentedString(parameters)).append("\n");
        sb.append("}");
        return sb.toString();
    }

    /**
     * Convert the given object to string with each line indented by 4 spaces
     * (except the first line).
     */
    private String toIndentedString(Object o) {
        if (o == null) {
            return "null";
        }
        return o.toString().replace("\n", "\n    ");
    }
}

